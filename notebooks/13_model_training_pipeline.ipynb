{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 3.0.5 may not be compatible with the connected Hopsworks backend version 3.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.2) by running 'pip install hopsworks==3.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/27802\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# connect to the project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value = config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature View already exists\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/27802/featurestores/27722/featureview/time_serie_hourly_feature_view/version/2). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 270181, error msg: Feature view wasn't found., user msg: There exists no feature view with the name time_serie_hourly_feature_view and version 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFeature View already exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m#get feature view\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m feature_view \u001b[39m=\u001b[39m feature_store\u001b[39m.\u001b[39;49mget_feature_view(\n\u001b[0;32m     17\u001b[0m     name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mFEATURE_VIEW_NAME,\n\u001b[0;32m     18\u001b[0m     version\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mFEATURE_VIEW_VERSION,\n\u001b[0;32m     19\u001b[0m ) \n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\feature_store.py:975\u001b[0m, in \u001b[0;36mFeatureStore.get_feature_view\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m    968\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    969\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo version provided for getting feature view `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`, defaulting to `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    970\u001b[0m             name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_VERSION\n\u001b[0;32m    971\u001b[0m         ),\n\u001b[0;32m    972\u001b[0m         util\u001b[39m.\u001b[39mVersionWarning,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m     version \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_VERSION\n\u001b[1;32m--> 975\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_engine\u001b[39m.\u001b[39;49mget(name, version)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\core\\feature_view_engine.py:78\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, name, version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m version:\n\u001b[1;32m---> 78\u001b[0m         fv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_api\u001b[39m.\u001b[39;49mget_by_name_version(name, version)\n\u001b[0;32m     79\u001b[0m         fv\u001b[39m.\u001b[39mtransformation_functions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_attached_transformation_fn(\n\u001b[0;32m     80\u001b[0m             fv\u001b[39m.\u001b[39mname, fv\u001b[39m.\u001b[39mversion\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\core\\feature_view_api.py:98\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot get back the feature view because the query defined is no longer valid.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Some feature groups used in the query may have been deleted. You can clean up this feature view on the UI\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m or `FeatureView.clean`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\core\\feature_view_api.py:86\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m     83\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path \u001b[39m+\u001b[39m [name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_VERSION, version]\n\u001b[0;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m feature_view\u001b[39m.\u001b[39mFeatureView\u001b[39m.\u001b[39mfrom_response_json(\n\u001b[1;32m---> 86\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_send_request(\n\u001b[0;32m     87\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_GET, path, {\u001b[39m\"\u001b[39;49m\u001b[39mexpand\u001b[39;49m\u001b[39m\"\u001b[39;49m: [\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m]}\n\u001b[0;32m     88\u001b[0m         )\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m \u001b[39mexcept\u001b[39;00m RestAPIError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mjson()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrorCode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m270009\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inst\u001b[39m.\u001b[39m_connected:\n\u001b[0;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[1;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Roaming\\pypoetry\\venv\\lib\\site-packages\\hsfs\\client\\base.py:171\u001b[0m, in \u001b[0;36mClient._send_request\u001b[1;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[0;32m    168\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39msend(prepped, verify\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verify, stream\u001b[39m=\u001b[39mstream)\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[1;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/27802/featurestores/27722/featureview/time_serie_hourly_feature_view/version/2). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 270181, error msg: Feature view wasn't found., user msg: There exists no feature view with the name time_serie_hourly_feature_view and version 2."
     ]
    }
   ],
   "source": [
    "# create feature view (if it doesn't exist yet) \n",
    "    #create feature view if it doesn't exist yet\n",
    "\n",
    "try:\n",
    "\n",
    "    feature_store.create_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "        query=feature_group.select_all()\n",
    "    )\n",
    "except:\n",
    "    print(\"Feature View already existed. Skip creation\")\n",
    "    \n",
    "\n",
    "#get feature view\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME,\n",
    "    version=config.FEATURE_VIEW_VERSION,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_view' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ts_data, _ \u001b[39m=\u001b[39m feature_view\u001b[39m.\u001b[39mtraining_data(\n\u001b[0;32m      2\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTime-series hourly taxi rides\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_view' is not defined"
     ]
    }
   ],
   "source": [
    "ts_data, _ = feature_view.training_data(\n",
    "    description='Time-series hourly taxi rides',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.sort_values(by=['pickup_location_id', 'pickup_hour'], inplace=True)\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.plot import plot_ts\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "\n",
    "def plot_ts(\n",
    "    ts_data: pd.DataFrame,\n",
    "    locations: Optional[List[int]] = None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Plot time-series data\n",
    "    \"\"\"\n",
    "    ts_data_to_plot = ts_data[ts_data.pickup_location_id.isin(locations)] if locations else ts_data\n",
    "\n",
    "    fig = px.line(\n",
    "        ts_data_to_plot,\n",
    "        x=\"pickup_hour\",\n",
    "        y=\"rides\",\n",
    "        color='pickup_location_id',\n",
    "        template='none',\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_ts(ts_data, locations=[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import transform_ts_data_into_features_and_target\n",
    "\n",
    "features, targets = transform_ts_data_into_features_and_target(\n",
    "    ts_data,\n",
    "    input_seq_len=24*28, #one month\n",
    "    step_size=23\n",
    ")\n",
    "\n",
    "features_and_target = features.copy()\n",
    "features_and_target['target_rides_next_hour'] = targets\n",
    "\n",
    "print(f'{features_and_target.shape=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "from src.data_split import train_test_split\n",
    "\n",
    "cutoff_date= pd.to_datetime(pd.Timestamp('2023-01-12 12:00:00') - timedelta(days=28*1))\n",
    "\n",
    "print(f'{cutoff_date=}')\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    features_and_target,\n",
    "    cutoff_date,\n",
    "    target_column_name='target_rides_next_hour'\n",
    ")\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "from src.model import get_pipeline\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Given a set of hyper-parameters, it trains a model and computes an average\n",
    "    validation error based on a TimeSeriesSplit\n",
    "    \"\"\"\n",
    "    # pick hyper-parameters \n",
    "    hyperparams = {\n",
    "        \"metric\":'mae',\n",
    "        \"verbose\": -1,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 100),\n",
    "    }\n",
    "\n",
    "    tss = TimeSeriesSplit(n_splits=2)\n",
    "    scores = []\n",
    "    for train_index, val_index in tss.split(X_train):\n",
    "\n",
    "        #Split data for training and validation\n",
    "        X_train_, X_val_ = X_train.iloc[train_index, :], X_train.iloc[val_index,:]\n",
    "        y_train_, y_val_ = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        #train the model\n",
    "        pipeline = get_pipeline(**hyperparams)\n",
    "        pipeline.fit(X_train_, y_train_)\n",
    "\n",
    "        # evaluate the model\n",
    "        y_pred = pipeline.predict(X_val_)\n",
    "        mae=mean_absolute_error(y_val_, y_pred)\n",
    "\n",
    "        scores.append(mae)\n",
    "\n",
    "    # Return the mean score\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(**best_params)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'{test_mae = :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "joblib.dump(pipeline, MODELS_DIR /'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = project.get_model_registry()\n",
    "\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"taxi_demand_predictor_next_hour\",\n",
    "    metrics={\"test_mae\": test_mae},\n",
    "    description=\"LightGBM regressor with a bit of hyper-parameter tuning\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save(MODELS_DIR / 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00b3ddb094b9e04fe59f4de86d62e52dc048dee5413d04c7b5b92444639cf601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
